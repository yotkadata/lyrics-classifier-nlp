{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "_Project for week 4, by Jan KÃ¼hn, April 2023_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project task and outline\n",
    "\n",
    "In this project, we will build a text classification model on song lyrics. The task is to predict the artist from a piece of text. To train such a model, you first need to collect your own lyrics dataset:\n",
    "\n",
    "- Download a HTML page with links to songs\n",
    "- Extract hyperlinks of song pages\n",
    "- Download and extract the song lyrics\n",
    "- Vectorize the text using the Bag Of Words method\n",
    "- Train a classification model that predicts the artist from a piece of text\n",
    "- Refactor the code into functions\n",
    "- Write a simple command-line interface for the program\n",
    "- Upload your code to GitHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from includes import misc, modelling, parse\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data needed for this project\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRAPE_SONG_LIST = False\n",
    "SCRAPE_SONGS = False\n",
    "PARSE_HTML = False\n",
    "CREATE_WORDCLOUDS = False\n",
    "SLEEP_SEC = 3\n",
    "HEADER = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:108.0) Gecko/20100101 Firefox/108.0\"\n",
    "}\n",
    "artist_urls = {\n",
    "    \"Eels\": \"https://www.lyrics.com/artist.php?name=Eels&aid=182509&o=1\",\n",
    "    \"Rage Against the Machine\": \"https://www.lyrics.com/artist.php?name=Rage-Against-the-Machine&aid=23206&o=1\",\n",
    "    \"Adele\": \"https://www.lyrics.com/artist.php?name=Adele&aid=861756&o=1\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PARSE_HTML:\n",
    "    # Get song URLs\n",
    "    song_urls = parse.get_song_urls(artist_urls)\n",
    "\n",
    "    # Parse lyrics from file and save them in a CSV file\n",
    "    songs = parse.parse_lyrics_from_files(song_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"data/songs_clean.csv\", index_col=0)\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = misc.convert_lyrics_to_lines(songs)\n",
    "df_corpus[\"artist\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_WORDCLOUDS:\n",
    "    corpus = \" \".join(df_corpus[df_corpus[\"artist\"] == \"Eels\"][\"lyrics\"])\n",
    "    misc.plot_wordcloud(corpus, name=\"Eels\", shape=\"circle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rage Against the Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_WORDCLOUDS:\n",
    "    corpus = \" \".join(\n",
    "        df_corpus[df_corpus[\"artist\"] == \"Rage Against the Machine\"][\"lyrics\"]\n",
    "    )\n",
    "    misc.plot_wordcloud(corpus, name=\"ratm\", shape=\"text\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_WORDCLOUDS:\n",
    "    corpus = \" \".join(\n",
    "        df_corpus[df_corpus[\"artist\"] == \"Adele\"][\"lyrics\"]\n",
    "    )\n",
    "    misc.plot_wordcloud(corpus, name=\"Adele\", shape=\"circle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare corpus and labels\n",
    "CORPUS, LABELS = modelling.prepare_corpus(df_corpus)\n",
    "assert(len(CORPUS) == len(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "CORPUS_CLEAN = modelling.preprocess_corpus(CORPUS)\n",
    "assert(len(CORPUS_CLEAN) == len(LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stop words\n",
    "STOPWORDS = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"tdidf\", TfidfVectorizer(stop_words=STOPWORDS)),\n",
    "        (\"nb\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"nb__alpha\": [0.1, 0.5, 1, 2, 3],\n",
    "    \"nb__fit_prior\": [True, False],\n",
    "    \"tdidf__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "}\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# initial time\n",
    "ti = time.time()\n",
    "\n",
    "# grid-search cross-validation\n",
    "gscv.fit(CORPUS_CLEAN, LABELS)\n",
    "\n",
    "# final time\n",
    "tf = time.time()\n",
    "\n",
    "# time taken\n",
    "print(f\"time taken: {round(tf-ti,2)} sec\")\n",
    "\n",
    "print(f\"Best parameters: {gscv.best_params_}\")\n",
    "print(f\"Best score: {round(gscv.best_score_,6)}\")\n",
    "\n",
    "model = gscv.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with the vectorized data\n",
    "model.fit(CORPUS_CLEAN, LABELS)\n",
    "\n",
    "# Check score\n",
    "model.score(CORPUS_CLEAN, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the trained model to predict for new lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = [\n",
    "    \"From the era of terror, check this photo lens\",\n",
    "    \"beautiful freak\",\n",
    "    \"Fuck you I won't do what you tell me\",\n",
    "    \"Bombtrack\",\n",
    "    \"the mistakes of my youth\",\n",
    "    \"Check it, since fifteen hundred and sixteen, minds attacked and overseen\",\n",
    "    \"Shock around tha clock, from noon 'til noon\",\n",
    "    \"When I came into this world they slapped me\",\n",
    "    \"Or should I just keep chasing pavements?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "lyrics_clean = modelling.preprocess_corpus(lyrics)\n",
    "\n",
    "# Get results\n",
    "predictions = model.predict(lyrics_clean)\n",
    "probabilities = [p.max() for p in model.predict_proba(lyrics_clean)]\n",
    "\n",
    "# Print results\n",
    "modelling.print_results(lyrics, predictions, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_asking = True\n",
    "\n",
    "while keep_asking:\n",
    "    user_input = input(\"Enter a line from a song by the Eels, Adele, or Rage Against the Machine\")\n",
    "\n",
    "    if user_input in [\"quit\", \"q\", \"exit\"]:\n",
    "        keep_asking = False\n",
    "        continue\n",
    "\n",
    "    lyrics = [user_input]\n",
    "\n",
    "    # Preprocess\n",
    "    lyrics_clean = modelling.preprocess_corpus(lyrics)\n",
    "\n",
    "    # Get results\n",
    "    predictions = model.predict(lyrics_clean)\n",
    "    probabilities = [p.max() for p in model.predict_proba(lyrics_clean)]\n",
    "\n",
    "    # Print results\n",
    "    modelling.print_results(lyrics, predictions, probabilities)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
