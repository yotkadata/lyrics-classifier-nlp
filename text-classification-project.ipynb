{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying song lyrics using Natural Language Processing (NLP)\n",
    "\n",
    "_Project by Jan KÃ¼hn, April 2023_\n",
    "\n",
    "In this project, we build a text classification model on song lyrics. The task is to predict the artist from a piece of text. To train such a model, we first need to collect a lyrics dataset. We will\n",
    "\n",
    "- Download a HTML page from lyrics.com with links to songs using the `requests` library\n",
    "- Extract hyperlinks of song pages using the `BeautifulSoup` library\n",
    "- Download and extract the song lyrics and save them to a temporary CSV file using the `requests` and `pandas` libraries\n",
    "- Clean and preprocess the lyrics using `TreebankWordTokenizer` and `WordNetLemmatizer` from the `nltk` library\n",
    "- Vectorize the text using `TfidfVectorizer` from the `sklearn` library\n",
    "- Build and hypertune a classification model using Naive Bayes classifier for multinomial models (`MultinomialNB`)\n",
    "- Predict the artist from a piece of text based on the trained model\n",
    "\n",
    "The heavy lifting is done in the functions defined in `includes`. We import them here and use them to build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "Most libraries are imported in the files we import from `includes`, we just need to import Pandas, the functions we defined in `includes`, and the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from includes.misc import convert_lyrics_to_lines, plot_wordcloud\n",
    "from includes.modelling import (load_model, prepare_corpus, preprocess_corpus,\n",
    "                                print_results, tune_hyperparameters)\n",
    "from includes.parse import parse_lyrics_from_files\n",
    "from includes.scrape import scrape_artist_song_list, scrape_songs_to_files\n",
    "from settings import conf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the lyrics\n",
    "\n",
    "First, we will download the HTML page from lyrics.com holding links to the artists songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_artist_song_list(conf[\"artist_urls\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we scrape the lyrics for each song in the song list and save them to HTML files locally. This will take a while, especially because of the `sleep_sec` time defined in `settings.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_songs_to_files(conf[\"artist_urls\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can parse the HTML files and save the lyrics to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = parse_lyrics_from_files(conf[\"artist_urls\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the CSV file already exists, we can also load it directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"data/songs_clean.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the lyrics into lines, with one DataFrame row for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = convert_lyrics_to_lines(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how lyric lines are distributed between artists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus[\"artist\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordclouds\n",
    "\n",
    "If we like, we can create wordclouds for each artist. This is not necessary for the model, but it's a nice visualization. There are three different shapes available: a circle, a rectangle, and a text of the author's name. For text, download the [Boldova font](https://www.cufonfonts.com/font/boldova) first and place the ttf in `data/Boldova.ttf`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(df_corpus[df_corpus[\"artist\"] == \"Eels\"][\"lyrics\"])\n",
    "plot_wordcloud(corpus, name=\"Eels\", shape=\"circle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rage Against the Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(\n",
    "    df_corpus[df_corpus[\"artist\"] == \"Rage Against the Machine\"][\"lyrics\"]\n",
    ")\n",
    "plot_wordcloud(corpus, name=\"ratm\", shape=\"rect\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(\n",
    "    df_corpus[df_corpus[\"artist\"] == \"Adele\"][\"lyrics\"]\n",
    ")\n",
    "plot_wordcloud(corpus, name=\"Adele\", shape=\"text\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Now we can build the model to be used for prediction later. If we skip the steps from before, we can import the corpus directly from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.read_csv(\"data/songs_by_line.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare corpus and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, labels = prepare_corpus(df_corpus)\n",
    "assert(len(corpus) == len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data (clean, tokenize, lemmatize)\n",
    "corpus_clean = preprocess_corpus(corpus)\n",
    "assert(len(corpus_clean) == len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model\n",
    "\n",
    "First we tune the hyperparameters for the TF-IDF vectorizer and the Multinomial Naive Bayes classifier. Then we instantiate the model with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tune_hyperparameters(corpus_clean, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of running hyperparameter tuning, you can also load a pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models/\", \"trained_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained model to predict for new lyrics\n",
    "\n",
    "We'll define some lyrics and predict the artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = [\n",
    "    \"From the era of terror, check this photo lens\",\n",
    "    \"beautiful freak\",\n",
    "    \"Fuck you I won't do what you tell me\",\n",
    "    \"Bombtrack\",\n",
    "    \"the mistakes of my youth\",\n",
    "    \"Check it, since fifteen hundred and sixteen, minds attacked and overseen\",\n",
    "    \"Shock around tha clock, from noon 'til noon\",\n",
    "    \"When I came into this world they slapped me\",\n",
    "    \"Or should I just keep chasing pavements?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "lyrics_clean = preprocess_corpus(lyrics)\n",
    "\n",
    "# Get results\n",
    "predictions = model.predict(lyrics_clean)\n",
    "probabilities = [p.max() for p in model.predict_proba(lyrics_clean)]\n",
    "\n",
    "# Print results\n",
    "print_results(lyrics, predictions, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lastly, we can do the same using direct user input\n",
    "\n",
    "Run the cell and then enter some lyrics. The model will predict the artist. To exit, write \"quit\", \"q\", or \"exit\" and hit enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_asking = True\n",
    "\n",
    "while keep_asking:\n",
    "    user_input = input(\"Enter a line from a song by the Eels, Adele, or Rage Against the Machine\")\n",
    "\n",
    "    if user_input in [\"quit\", \"q\", \"exit\"]:\n",
    "        keep_asking = False\n",
    "        continue\n",
    "\n",
    "    lyrics = [user_input]\n",
    "\n",
    "    # Preprocess\n",
    "    lyrics_clean = preprocess_corpus(lyrics)\n",
    "\n",
    "    # Get results\n",
    "    predictions = model.predict(lyrics_clean)\n",
    "    probabilities = [p.max() for p in model.predict_proba(lyrics_clean)]\n",
    "\n",
    "    # Print results\n",
    "    print_results(lyrics, predictions, probabilities)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
